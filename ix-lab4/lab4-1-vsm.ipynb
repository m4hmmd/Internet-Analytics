{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text 1: Vector space models\n",
    "**Internet Analytics - Lab 4**\n",
    "\n",
    "---\n",
    "\n",
    "**Group:** *B*\n",
    "\n",
    "**Names:**\n",
    "\n",
    "* *Keijiro Tajima*\n",
    "* *Mahammad Shirinov*\n",
    "* *Stephen Zhao*\n",
    "\n",
    "---\n",
    "\n",
    "#### Instructions\n",
    "\n",
    "*This is a template for part 1 of the lab. Clearly write your answers, comments and interpretations in Markodown cells. Don't forget that you can add $\\LaTeX$ equations in these cells. Feel free to add or remove any cell.*\n",
    "\n",
    "*Please properly comment your code. Code readability will be considered for grading. To avoid long cells of codes in the notebook, you can also embed long python functions and classes in a separate module. Don’t forget to hand in your module if that is the case. In multiple exercises, you are required to come up with your own method to solve various problems. Be creative and clearly motivate and explain your methods. Creativity and clarity will be considered for grading.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "from utils import load_json, load_pkl, save_pkl\n",
    "import string\n",
    "import re\n",
    "from nltk.stem import PorterStemmer as PS\n",
    "import math\n",
    "from numpy import linalg as LA\n",
    "\n",
    "courses = load_json('data/courses.txt')\n",
    "stopwords = load_pkl('data/stopwords.pkl')\n",
    "courses_original = load_json('data/courses.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4.1: Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of courses is 854.\n"
     ]
    }
   ],
   "source": [
    "# Check the number of courses\n",
    "print(\"The number of courses is {}.\".format(len(courses)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE-440\n",
      "The latest developments in processing and the novel generations of organic composites are discussed. Nanocomposites, adaptive composites and biocomposites are presented. Product development, cost analysis and study of new markets are practiced in team work. Content Basics of composite materialsConstituentsProcessing of compositesDesign of composite structures Current developmentNanocomposites Textile compositesBiocompositesAdaptive composites ApplicationsDriving forces and marketsCost analysisAerospaceAutomotiveSport Keywords Composites - Applications - Nanocomposites - Biocomposites - Adaptive composites - Design - Cost Learning Prerequisites Required courses Notion of polymers Recommended courses Polymer Composites Learning Outcomes By the end of the course, the student must be able to: Propose suitable design, production and performance criteria for the production of a composite partApply the basic equations for process and mechanical properties modelling for composite materialsDiscuss the main types of composite applications Transversal skills Use a work methodology appropriate to the task.Use both general and domain specific IT resources and toolsCommunicate effectively with professionals from other disciplines.Evaluate one's own performance in the team, receive and respond appropriately to feedback. Teaching methods Ex cathedra and invited speakers Group sessions with exercises or work on the project Expected student activities Attendance at lectures Design of a composite part, bibliography search   Assessment methods Written exam report and oral presentation in class\n"
     ]
    }
   ],
   "source": [
    "# Check the first course's description without pre-processing\n",
    "print(courses[0]['courseId'])\n",
    "print(courses[0]['description'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split camel case words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CAPITAL_LETTERS = ''.join(chr(ord('A') + i) for i in range(26))\n",
    "\n",
    "for course in courses:\n",
    "    desc_lst = []\n",
    "    for word in course['description'].split():\n",
    "        # Split up camelcase words like \"materialsConstituentsProcessing\" \n",
    "        # that were not parsed correctly and ended up as camel case.\n",
    "        # But do not split up acronyms like \"IT\"\n",
    "        words = []\n",
    "        if len(word) == 1:\n",
    "            words.append(word)\n",
    "        else:\n",
    "            for i in range(len(word)):\n",
    "                if i == 0: # Start the first word\n",
    "                    start = 0\n",
    "                elif i == len(word)-1: # Add the final word\n",
    "                    words.append(word[start:])\n",
    "                else:\n",
    "                    is_prev_capital = word[i-1] in CAPITAL_LETTERS\n",
    "                    is_curr_capital = word[i] in CAPITAL_LETTERS\n",
    "                    is_next_capital = word[i+1] in CAPITAL_LETTERS\n",
    "                    if is_curr_capital:\n",
    "                        if is_prev_capital:\n",
    "                            if is_next_capital:\n",
    "                                # part of acronym\n",
    "                                continue\n",
    "                            else:\n",
    "                                # end of acronym and beginning of new word\n",
    "                                words.append(word[start:i])\n",
    "                                start = i\n",
    "                        else:\n",
    "                            # start of new word or acronym\n",
    "                            start = i\n",
    "                    else:\n",
    "                        if is_next_capital:\n",
    "                            # end of a word or acronym\n",
    "                            words.append(word[start:i+1])\n",
    "                        else:\n",
    "                            # part of a word\n",
    "                            continue       \n",
    "                        #endif\n",
    "                    #endif\n",
    "                #endif\n",
    "            #endfor\n",
    "        #endif\n",
    "        desc_lst += words\n",
    "    course['description'] = ' '.join(desc_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE-440\n",
      "The latest developments in processing and the novel generations of organic composites are discussed. Nanocomposites, adaptive composites and biocomposites are presented. Product development, cost analysis and study of new markets are practiced in team work. Content Basics of composite materials Constituents Processing of composites Design of composite structures Current development Nanocomposites Textile composites Biocomposites Adaptive composites Applications Driving forces and markets Cost analysis Aerospace Automotive Sport Keywords Composites - Applications - Nanocomposites - Biocomposites - Adaptive composites - Design - Cost Learning Prerequisites Required courses Notion of polymers Recommended courses Polymer Composites Learning Outcomes By the end of the course, the student must be able to: Propose suitable design, production and performance criteria for the production of a composite part Apply the basic equations for process and mechanical properties modelling for composite materials Discuss the main types of composite applications Transversal skills Use a work methodology appropriate to the task. Use both general and domain specific IT resources and tools Communicate effectively with professionals from other disciplines. Evaluate one's own performance in the team, receive and respond appropriately to feedback. Teaching methods Ex cathedra and invited speakers Group sessions with exercises or work on the project Expected student activities Attendance at lectures Design of a composite part, bibliography search Assessment methods Written exam report and oral presentation in class\n"
     ]
    }
   ],
   "source": [
    "# Check the first course's description after camel case splitting\n",
    "print(courses[0]['courseId'])\n",
    "print(courses[0]['description'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Remove the punctuation (except apostrophe which is used in stop words)\n",
    "punctuation_table = \"[{}]+\".format(re.escape(string.punctuation.replace(\"\\'\", '')))\n",
    "\n",
    "for course in courses:\n",
    "    course['description'] = re.sub(punctuation_table, ' ', course['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE-440\n",
      "The latest developments in processing and the novel generations of organic composites are discussed  Nanocomposites  adaptive composites and biocomposites are presented  Product development  cost analysis and study of new markets are practiced in team work  Content Basics of composite materials Constituents Processing of composites Design of composite structures Current development Nanocomposites Textile composites Biocomposites Adaptive composites Applications Driving forces and markets Cost analysis Aerospace Automotive Sport Keywords Composites   Applications   Nanocomposites   Biocomposites   Adaptive composites   Design   Cost Learning Prerequisites Required courses Notion of polymers Recommended courses Polymer Composites Learning Outcomes By the end of the course  the student must be able to  Propose suitable design  production and performance criteria for the production of a composite part Apply the basic equations for process and mechanical properties modelling for composite materials Discuss the main types of composite applications Transversal skills Use a work methodology appropriate to the task  Use both general and domain specific IT resources and tools Communicate effectively with professionals from other disciplines  Evaluate one's own performance in the team  receive and respond appropriately to feedback  Teaching methods Ex cathedra and invited speakers Group sessions with exercises or work on the project Expected student activities Attendance at lectures Design of a composite part  bibliography search Assessment methods Written exam report and oral presentation in class\n"
     ]
    }
   ],
   "source": [
    "# Check the first course's description \n",
    "print(courses[0]['courseId'])\n",
    "print(courses[0]['description'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove stop words, then remove leftover apostrophes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function that remove all the words in a words_list from course descriptions\n",
    "def remove(words_lst):\n",
    "    for course in courses:\n",
    "        desc_lst = course['description'].split()\n",
    "        for word in words_lst:\n",
    "            if word in desc_lst:\n",
    "                desc_lst = list(filter(lambda x: x != word, desc_lst))\n",
    "        course['description'] = ' '.join(desc_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function that capitalizes all the words in a words_list\n",
    "def capitalize_words(words_lst):\n",
    "    a = set([])\n",
    "    for i in words_lst:\n",
    "        a.add(i.capitalize())\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "capitalized_stopwords = capitalize_words(list(stopwords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Remove the stopwords and capitalized_stopwords\n",
    "remove(list(stopwords))\n",
    "remove(list(capitalized_stopwords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Remove hanging apostrophes to join possesive \"s\" with the word\n",
    "for course in courses:\n",
    "    course['description'] = course['description'].replace(\"'\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE-440\n",
      "latest developments processing generations organic composites discussed Nanocomposites adaptive composites biocomposites presented Product development cost analysis study markets practiced team work Content Basics composite materials Constituents Processing composites Design composite structures Current development Nanocomposites Textile composites Biocomposites Adaptive composites Applications Driving forces markets Cost analysis Aerospace Automotive Sport Keywords Composites Applications Nanocomposites Biocomposites Adaptive composites Design Cost Learning Prerequisites Required courses Notion polymers Recommended courses Polymer Composites Learning Outcomes end student Propose suitable design production performance criteria production composite part Apply basic equations process mechanical properties modelling composite materials Discuss main types composite applications Transversal skills work methodology task general domain specific IT resources tools Communicate effectively professionals disciplines Evaluate ones performance team receive respond appropriately feedback Teaching methods cathedra invited speakers Group sessions exercises work project Expected student activities Attendance lectures Design composite part bibliography search Assessment methods Written exam report oral presentation class\n"
     ]
    }
   ],
   "source": [
    "# Check the first course's description without stop words\n",
    "print(courses[0]['courseId'])\n",
    "print(courses[0]['description'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stem the words with nltk library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ps = PS()\n",
    "\n",
    "for course in courses:\n",
    "    desc_lst = course['description'].split()\n",
    "    for i in range(len(desc_lst)):\n",
    "        desc_lst[i] = ps.stem(desc_lst[i])\n",
    "    course['description'] = course['description'] = ' '.join(desc_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE-440\n",
      "latest develop process gener organ composit discuss nanocomposit adapt composit biocomposit present product develop cost analysi studi market practic team work content basic composit materi constitu process composit design composit structur current develop nanocomposit textil composit biocomposit adapt composit applic drive forc market cost analysi aerospac automot sport keyword composit applic nanocomposit biocomposit adapt composit design cost learn prerequisit requir cours notion polym recommend cours polym composit learn outcom end student propos suitabl design product perform criteria product composit part appli basic equat process mechan properti model composit materi discuss main type composit applic transvers skill work methodolog task gener domain specif IT resourc tool commun effect profession disciplin evalu one perform team receiv respond appropri feedback teach method cathedra invit speaker group session exercis work project expect student activ attend lectur design composit part bibliographi search assess method written exam report oral present class\n"
     ]
    }
   ],
   "source": [
    "# Check the first course's description\n",
    "print(courses[0]['courseId'])\n",
    "print(courses[0]['description'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the frequent and infrequent words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make frequent words list and infrequent words list\n",
    "frequency_dict = {}\n",
    "for course in courses:\n",
    "    for word in course['description'].split():\n",
    "            if word in frequency_dict:\n",
    "                frequency_dict[word] += 1\n",
    "            else:\n",
    "                frequency_dict[word] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of words: 9758\n"
     ]
    }
   ],
   "source": [
    "# See the number of unique words we have\n",
    "print('num of words:', len(frequency_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "frequency_sorted = sorted(frequency_dict.items(), key=lambda x:x[1], reverse = True)\n",
    "infrequency_sorted = sorted(frequency_dict.items(), key=lambda x:x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('student', 2053),\n",
       " ('method', 1814),\n",
       " ('learn', 1633),\n",
       " ('model', 1240),\n",
       " ('system', 1201),\n",
       " ('assess', 1017),\n",
       " ('design', 991),\n",
       " ('content', 923),\n",
       " ('present', 793),\n",
       " ('process', 792)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Top 10 frequent words\n",
    "frequency_sorted[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('imagej', 1),\n",
       " ('fiji', 1),\n",
       " ('1h30', 1),\n",
       " ('metadata', 1),\n",
       " ('stitch', 1),\n",
       " ('fij', 1),\n",
       " ('nontrad', 1),\n",
       " ('begiven', 1),\n",
       " ('statiqu', 1),\n",
       " ('102', 1)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Top 10 infrequent words\n",
    "infrequency_sorted[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequent and infrequent words\n",
    "- Frequent words, like 'student' and 'method', are very general and don't affect the courses' characteristics. \n",
    "- Also infrequent words, like 'imagej' and 'fiji', are too specialized and not useful for characterising courses.\n",
    "\n",
    "Let's remove these words. Frequent words are not so many but dominant, so remove 0.1% (around the top 10) of frequent words. Remove all infrequent words that appear only once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function that extracts a certain percentage of words from a words_lst.\n",
    "def extract(words_lst, percent):\n",
    "    removed = 0\n",
    "    taken_lst = []\n",
    "    while removed <= len(words_lst)*percent*0.01:\n",
    "        taken_lst.append(words_lst[removed][0])\n",
    "        removed += 1\n",
    "    return taken_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of frequent words:    10\n",
      "num of infrequent words:  4282\n"
     ]
    }
   ],
   "source": [
    "# Extract 0.1% of frequent words and all infrequent (freq=1) words.\n",
    "frequent_words = extract(frequency_sorted, 0.1)\n",
    "infrequent_words = [word for word, freq in infrequency_sorted if freq <= 1]\n",
    "print(\"num of frequent words:   \", len(frequent_words))\n",
    "print(\"num of infrequent words: \", len(infrequent_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "remove(frequent_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "remove(infrequent_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE-440\n",
      "latest develop gener organ composit discuss nanocomposit adapt composit biocomposit product develop cost analysi studi market practic team work basic composit materi constitu composit composit structur current develop nanocomposit textil composit biocomposit adapt composit applic drive forc market cost analysi aerospac automot sport keyword composit applic nanocomposit biocomposit adapt composit cost prerequisit requir cours notion polym recommend cours polym composit outcom end propos suitabl product perform criteria product composit part appli basic equat mechan properti composit materi discuss main type composit applic transvers skill work methodolog task gener domain specif IT resourc tool commun effect profession disciplin evalu one perform team receiv respond appropri feedback teach cathedra invit speaker group session exercis work project expect activ attend lectur composit part bibliographi search written exam report oral class\n"
     ]
    }
   ],
   "source": [
    "# Check the first course's description\n",
    "print(courses[0]['courseId'])\n",
    "print(courses[0]['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_pkl(courses, 'courses_prepped.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Explain which ones you implemented and why.\n",
    "\n",
    "- We implemented removing stopwords, punctuation, the very frequent words, the infrequent words, the stem words .\n",
    "- Clearly, stopwords and punctuation are needless for characterizing courses.\n",
    "- Also, as we mentioned in the \"frequent and infrequent words part\", frequent words are too general and infrequent words like 'imagej' and 'fiji', are too specialized and not useful for characterising courses. Therefore we removed them.\n",
    "- For the stemming and lemmatise, they are similar ones, so I chose stemming for this project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Print the terms in the pre-processed description of the IX class in alphabetical order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['20', '30', '300', '50', 'CO', 'acquir', 'activ', 'ad', 'ad', 'advertis', 'algebra', 'algebra', 'algorithm', 'algorithm', 'analysi', 'analyt', 'analyt', 'analyz', 'applic', 'applic', 'auction', 'auction', 'balanc', 'base', 'base', 'basic', 'basic', 'basic', 'cathedra', 'chain', 'class', 'class', 'class', 'cloud', 'cluster', 'cluster', 'collect', 'combin', 'commerc', 'commerc', 'commun', 'commun', 'commun', 'comput', 'comput', 'concept', 'concept', 'concret', 'contain', 'cours', 'cours', 'coverag', 'current', 'data', 'data', 'data', 'data', 'data', 'data', 'dataset', 'dataset', 'decad', 'dedic', 'detect', 'detect', 'develop', 'dimension', 'draw', 'effect', 'effici', 'end', 'exam', 'expect', 'explor', 'explor', 'explor', 'explor', 'explor', 'field', 'final', 'foundat', 'framework', 'function', 'fundament', 'good', 'graph', 'graph', 'hadoop', 'hadoop', 'hand', 'homework', 'homework', 'import', 'inform', 'inform', 'infrastructur', 'inspir', 'internet', 'internet', 'java', 'key', 'keyword', 'knowledg', 'lab', 'lab', 'lab', 'laboratori', 'larg', 'larg', 'larg', 'lectur', 'lectur', 'linear', 'linear', 'machin', 'machin', 'main', 'map', 'markov', 'materi', 'materi', 'media', 'midterm', 'mine', 'mine', 'mine', 'mine', 'network', 'network', 'network', 'network', 'number', 'number', 'onlin', 'onlin', 'onlin', 'onlin', 'onlin', 'outcom', 'past', 'practic', 'practic', 'prerequisit', 'problem', 'problem', 'project', 'provid', 'question', 'real', 'real', 'real', 'real', 'real', 'recommend', 'recommend', 'recommend', 'reduc', 'reduct', 'relat', 'requir', 'retriev', 'retriev', 'scale', 'scale', 'scale', 'search', 'search', 'seek', 'servic', 'servic', 'servic', 'servic', 'servic', 'session', 'session', 'social', 'social', 'social', 'social', 'social', 'spark', 'specif', 'start', 'statist', 'stochast', 'stream', 'stream', 'structur', 'teach', 'techniqu', 'theoret', 'theori', 'topic', 'topic', 'typic', 'ubiquit', 'user', 'weekli', 'work', 'world', 'world', 'world', 'world', 'world']\n"
     ]
    }
   ],
   "source": [
    "a = 0\n",
    "for i in courses:\n",
    "    if i['courseId'] == 'COM-308':\n",
    "        ix_desc = i['description'].split()\n",
    "        ix_desc.sort()\n",
    "        print(ix_desc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4.2: Term-document matrix\n",
    "- computation of TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of all words used in the courses' descriptions is 5466.\n"
     ]
    }
   ],
   "source": [
    "# Make a set that contains all the words in the courses.\n",
    "all_lst = []\n",
    "for course in courses:\n",
    "    for word in course['description'].split():\n",
    "        all_lst.append(word)\n",
    "all_set = set(all_lst)\n",
    "print(\"The number of all words used in the courses' descriptions is {}.\".format(len(all_set)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5466, 854)"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Construct the TF matrix\n",
    "TF_matrix = np.zeros((len(all_set),len(courses)))\n",
    "TF_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make indices for column (courseIds) and row (words).\n",
    "column_indices = [x['courseId'] for x in courses]\n",
    "row_indices = list(all_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i, word in enumerate(row_indices):\n",
    "    for j, course in enumerate(courses):\n",
    "        desc_lst = course['description'].split()\n",
    "        occur_time = desc_lst.count(word)\n",
    "        TF_matrix[i][j] = occur_time/len(desc_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "IDF = np.zeros(len(all_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Construct the IDF\n",
    "for row in range(len(row_indices)):\n",
    "    course_sum = np.sum(TF_matrix[row] != 0)\n",
    "    IDF[row] = math.log(len(courses)/course_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "IDF = IDF.reshape(len(IDF),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.89978359],\n",
       "       [ 0.98787981],\n",
       "       [ 3.38263536],\n",
       "       ..., \n",
       "       [ 5.65131891],\n",
       "       [ 6.74993119],\n",
       "       [ 6.05678401]])"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Construct the TFIDF_matrix\n",
    "TFIDF_matrix = TF_matrix*IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5466, 854)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TFIDF_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.01555716,  0.01829407,  0.        , ...,  0.        ,\n",
       "         0.03186709,  0.03951519],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       ..., \n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ]])"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TFIDF_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_pkl(TFIDF_matrix, 'tfidx_matrix.pkl')\n",
    "save_pkl(column_indices, 'courses.pkl')\n",
    "save_pkl(row_indices, 'terms.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Take the TFIDF values of  'COM-308'\n",
    "ix_index = column_indices.index('COM-308')\n",
    "ix_word = TFIDF_matrix[:, ix_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ix_TFIDF_vals = {}\n",
    "for i, val in enumerate(ix_word):\n",
    "    if not val > 0.0:\n",
    "        continue\n",
    "    ix_TFIDF_vals[row_indices[i]] = val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Print the 15 terms in the description of the IX class with the highest TF-IDF scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('mine', 0.091578228472720277),\n",
       " ('servic', 0.087546013809819231),\n",
       " ('onlin', 0.084659174700594128),\n",
       " ('social', 0.076936600028047683),\n",
       " ('world', 0.070557112325506835),\n",
       " ('explor', 0.069556573244128034),\n",
       " ('hadoop', 0.059380235423810046),\n",
       " ('real', 0.055980957723872203),\n",
       " ('auction', 0.052584674830085089),\n",
       " ('commerc', 0.052584674830085089),\n",
       " ('retriev', 0.047098245536600553),\n",
       " ('internet', 0.045789114236360139),\n",
       " ('network', 0.045240783084279479),\n",
       " ('dataset', 0.041029233689480714),\n",
       " ('stream', 0.039626284242023135)]"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the 15 terms in the description of the IX class with the highest TF-IDF scores.\n",
    "ix_TFIDF_vals_sorted = sorted(ix_TFIDF_vals.items(), key=lambda x:x[1], reverse = True)\n",
    "ix_TFIDF_vals_sorted[0:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Explain where the difference between the large scores and the small ones comes from.\n",
    "\n",
    "- Compared to the top words, like 'onlin' or 'realworld', some words like 'model' and 'data' occured in the description of IX class. However their TFIDF values are relatively small. The reason is that these words like 'model' and 'data' also occur in other courses' descriptions. Frequency for all descriptions is the defference between the large scores and the small ones comes from."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4.3: Document similarity search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Construct query vectors for markov chain and facebook\n",
    "markov_chain = np.zeros(len(row_indices)).reshape(len(row_indices),1)\n",
    "markov_chain[row_indices.index('markov')] = 1/2\n",
    "markov_chain[row_indices.index('chain')] = 1/2\n",
    "\n",
    "facebook = np.zeros(len(row_indices))\n",
    "facebook[row_indices.index('facebook')] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function that calculates the cosine similarity of  2 documents\n",
    "def similarity(di, dj):\n",
    "    return np.dot(di, dj) / (LA.norm(di) * LA.norm(dj))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "markov_similarity = []\n",
    "for i in range(len(column_indices)):\n",
    "    markov_similarity.append(similarity(TFIDF_matrix.T[i], markov_chain)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make a dictionary of (course name: similarity value)\n",
    "markov_sim_vals = {}\n",
    "for i, sim in enumerate(markov_similarity):\n",
    "    markov_sim_vals[courses[i]['name']] = sim\n",
    "    \n",
    "# Sort by similarity value\n",
    "markov_sim_vals_sorted = sorted(markov_sim_vals.items(), key=lambda x:x[1], reverse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "facebook_similarity = []\n",
    "for i in range(len(column_indices)):\n",
    "    facebook_similarity.append(similarity(TFIDF_matrix.T[i], facebook))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make a dictionary of (course name: similarity value)\n",
    "facebook_sim_vals = {}\n",
    "for i, sim in enumerate(facebook_similarity):\n",
    "    facebook_sim_vals[courses[i]['name']] = sim\n",
    "\n",
    "# Sort by similarity value\n",
    "facebook_sim_vals_sorted = sorted(facebook_sim_vals.items(), key=lambda x:x[1], reverse = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Display the top five courses together with their similarity score for each query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top five courses together with their similarity score for query markov chain\n",
      "('Applied stochastic processes', 0.58755084846323447)\n",
      "('Applied probability & stochastic processes', 0.53961015057965878)\n",
      "('Markov chains and algorithmic applications', 0.45636978045262666)\n",
      "('Supply chain management', 0.3903593823655549)\n",
      "('Mathematical models in supply chain management', 0.31751041450037115)\n"
     ]
    }
   ],
   "source": [
    "# Print the top 5 courses\n",
    "print(\"The top five courses together with their similarity score for query markov chain\")\n",
    "for i in range(5):\n",
    "    print(markov_sim_vals_sorted[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top five courses together with their similarity score for query facebook\n",
      "('Computational Social Media', 0.18591143220755649)\n",
      "('Composites technology', 0.0)\n",
      "('Image Processing for Life Science', 0.0)\n",
      "('Global business environment', 0.0)\n",
      "('Electrochemical nano-bio-sensing and bio/CMOS interfaces', 0.0)\n"
     ]
    }
   ],
   "source": [
    "# Print the top 5 courses\n",
    "print(\"The top five courses together with their similarity score for query facebook\")\n",
    "for i in range(5):\n",
    "    print(facebook_sim_vals_sorted[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. What do you think of the results? Give your intuition on what is happening."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "count_markov = 0\n",
    "count_chain = 0\n",
    "count_facebook = 0\n",
    "for course in courses:\n",
    "    for word in course['description'].split():\n",
    "        if word == 'markov':\n",
    "            count_markov += 1\n",
    "        if word == 'chain':\n",
    "            count_chain += 1\n",
    "        if word == 'facebook':\n",
    "            count_facebook += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of markov in descriptions is 45\n",
      "The number of chain in descriptions is 79\n",
      "The number of facebook in descriptions is 3\n"
     ]
    }
   ],
   "source": [
    "print(\"The number of markov in descriptions is {}\".format(count_markov))\n",
    "print(\"The number of chain in descriptions is {}\".format(count_chain))\n",
    "print(\"The number of facebook in descriptions is {}\".format(count_facebook))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For markov chain, the suggested top five courses look very related to markov chain.For facebook, most of the simirality values of suggested top five courses are 0. This means that this model cannot detect courses that relate to facebook. \n",
    "- According to the numbers mentioned above, facebook doesn't occur often in the descriptions. Therefore, the result shows that this TF-IDF model can detect courses related to the words which exactly occur in the descriptions many times. However, this model can't detect courses with words that are too concrete and don't occur in the descriptions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
